%-----------------------------Base----------------------------%
\documentclass[a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[autostyle=true]{csquotes} % Required to generate language-dependent quotes in the bibliography
\usepackage{geometry}
\geometry{
	paper=a4paper, % Change to letterpaper for US letter
	inner=2.5cm, % Inner margin
	outer=2.5cm, % Outer margin
	top=2.5cm, % Top margin
	bottom=2.5cm, % Bottom margin
	%showframe,% show how the type block is set on the page
}
\usepackage{booktabs}
\usepackage{setspace}
\onehalfspacing
\usepackage[colorlinks=true,citecolor=blue]{hyperref}

%-----------------------------MATH----------------------------%
\usepackage{amsmath}
\usepackage{amssymb}
\allowdisplaybreaks
%-----------------------------FONT----------------------------%
\usepackage{microtype} 
%-------------------GRAPHIC ---------------------%
\usepackage{float}
\usepackage{graphicx}
\graphicspath{{figures/}}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.5}

%-----------------------------BIBLIOGRAPHY--------------------%
\usepackage{natbib}

%-------------------THESIS INFORMATION-----------------%

\title{\textbf{Fluctuations in a Dual Labor Market}}
\author{Normann Rion\footnote{Ecole Normale SupÃ©rieure and Paris School of Economics. E-mail: \href{mailto:normann.rion@psemail.eu}{\texttt{normann.rion@psemail.eu}}}}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
\textbf{JEL Classification:} \\
\textbf{Keywords:} 
\end{abstract}

\input{model}


\section{Calibration and estimation procedure}

The model is bridged to the data through two steps. Some of the parameters are firstly calibrated to match moments shaping typical dual European labor markets. Then, parameters driving shock processes and nominal rigidities are estimated through a Bayesian technique. 

\subsection{Calibration}

The intended calibration exercise needs to meet two requirements so as to lead to relevant results from an heuristic point of view. A natural objective is the faithful reproduction of the main features of labor markets in the Euro area. Moreover, the unprecedented modelisation of a dual labor market in a DSGE model adds the requirement of numerical comparability with a classic labor market embedding firing costs within the Euro Area. I shall rely on modelisation choices \citet{thomas2009labor} made to compel with the latter demand.

The central role of the distribution for idiosyncratic productivity shocks in the shaping of hiring and separation decisions falls reluctantly within the need for comparability, in absence of a proper estimation procedure. Consequently, I assume that the standard deviation for these shocks amounts to 0.2. I follow \citet{thomas2009labor} in several other dimensions. The discount factor is simarly set to 0.99. The matching function is assumed to be in a Cobb-Douglas form $m\left(e,v\right) = m e^{\sigma} v^{1-\sigma}$ with $\sigma$ set to 0.6, which stands in the middle of the 0.5-0.7 range \citet{burda1994gross} estimated for some European countries. The Hosios condition being still verified, I set the workers' bargaining power to 0.6 as well so that the congestion externalities do not weigh in. The elasticity of demand curves is set to 6. I also assume that the government-spending-to-gdp ratio is 20 \% .

\begin{table}[H]
\centering
\begin{tabular}{|c c c c c|}
\hline
$\beta$ & $\sigma$ & $\eta$ & $\sigma_z$ & $\epsilon$\\
\hline
0.99 & 0.6 & 0.6 & 0.2 & 6\\
\hline
\end{tabular}
\caption{Initial parameters \label{parameters}}
\end{table}

I depart from \citet{thomas2009labor} in several dimensions. I assume that the vacancy-worker meeting probability from the firm's point of view is 0.7 instead of 0.9. The latter figure replicates flows on the US labor market, which are known to be bigger than the European ones. One important feature of the labor market is its size, since it influences labor market tightness and job-finding rates. Should we consider ILO-defined unemployment \emph{stricto sensu} or include the inactive population ? \citet{elsby2015importance} and \citet{fontaine2016french} demonstrated the importance of the participation margin to explain unemployment fluctuations respectively in the United States and in France. This is all the more true with precarious employment, which involves people at the blurred frontier between unemployment and inactivity. According to data from Eurostat extending between 2002 and 2017, the participation rate in the Euro Area rate is around 67 \%. Thus, I set steady-state employment to 0.67. In the same manner, I target a ratio of temporary contracts over total employment of 13 \% in accordance with Eurostat estimates from 2006 to 2017. An important factor is the contractual composition of creation flows, which influences the rate of turnover in the labor force. Data from \emph{Acoss - Dares} witness that 80 \% of job creations occur through temporary contracts in France, a share that reaches 90 \% in Spain as \citet{RePEc:fda:fdaeee:eee2017-25} document. At the other end of the spectrum, \citet{addison2019worker} report a 45 \% share of temporary contracts in German job creation. I target a 70 \% share of fixed-term contracts in job creation to strike a balance. I also set the quarterly separation probability of permanent matches $\xi^p$ to 3 \% consistently with the magnitude of data from Eurostat. This leads to a steady-state separation probability of temporary matches of 40 \%, which is equivalent to an average duration of 7.5 months. This estimate is in line with Eurostat data. Among separations involving permanent contracts, an essential factor is the probability of paying the firing cost. \citet{jolivet:hal-00279066} explain that more sclerotic markets lead to a higher share of voluntary quits, whereas lay-offs tend to be more significant in countries with more flexible labor markets. The French case is described as the most representative of the former phenomenon, with 80 \% of separations involving permanent matches happening through voluntary channels according to \citet{dares062018}. A reasonable value for the Euro Area is thus inferior. As a result, I target a rate of 60 \% for the ratio of exogenous separations among total separations for permanent matches. The resulting value of $s$ is 2.1 \%.

The calibration of firing costs constitutes a challenge. The data is scarce about this issue, which makes reasonable proposals difficult to spell. The latter is all the more true since heterogeneity between countries is high, whether it be from a legal or an economic point of view. The 0-to-5 OECD indicator for employment protection legislation enables a cursory comparison between Euro area countries. While French, German and Italian indexes of EPL against collective and individual dismissals of permanent contracts are close to 2.8, the Spanish index is roughly 2.4. Employment protection legislation in the Euro Area seems closer to the French case, whose firing costs are examined by \citet{kramarz2010shape}. The latter assess that individual lay-offs marginally cost 4 months of the median wage, while the marginal cost of lay-off within a collective-termination plan represents 12 months of the median wage\footnote{To be accurate, \citet{kramarz2010shape} assess that firms with more than 50 employees face a marginal cost of 97,727 FFr (Table 1b), which represents 14 months of the workers' median wage. Consequently, the associated median wage of fired workers is 6980 FFr. Thus, Table 2 shows that individual terminations cost 27,389 FFr, which amounts to 4 months of the fired workers' median wage, while the termination within a collective firing plan marginally costs 81,850 FFr, which equals 12 months of the median wage.}. The former being the most frequent case, we reckon that total firing costs represent 4 months of the permanent workers' average wage . As in \citet{bentolila2012reforming} and \citet{doi:10.1111/iere.12167}, we assume that red-tape costs actually embodied by $F$ only represent one third of total firing costs for the firm\footnote{Transfers between separated firms and workers are not taken into account in firing costs because they play no allocational role, in contrast with red-tape firing costs}. Thus, we target a ratio of 4/9 for firing costs with respect to the quarterly permanent workers' average wage.

\begin{table}[H]
\centering
\begin{tabular}{|c c c c c c c|}
\hline
$F/\overline{w^p}$ & $\mu^f / \left( \mu^p + \mu^f \right)$ & $n^f / n$ & $\xi$ & $s / \xi $ &  $n$ & $q(\theta)$\\
\hline
4/9 & 0.7 & 0.15 & 0.03 & 0.6 & 0.67 & 0.7\\
\hline
\end{tabular}
\caption{Targets for a calibration of the labor market in the Euro area\label{targets}}
\end{table}

The last parameters to be pinpointed are $F,b,m,\rho$ and $\gamma$. The empirical evidence concerning $b$ is thin. Indeed, the flow value of non-employment is a highly debated issue in labor economics. \citet{10.1257/aer.98.4.1692} advocate a high relative value of non-employment with respect to employment to make the Mortensen-Pissarides model able to replicate faithfully fluctuations in unemployment and vacancies following productivity shocks of a  realistic magnitude. The high replacement ratios of unemployment insurance in Western Europe combined with the non-monetary benefits of working support this view. The obtained $b$ is coherent with this view. In the same manner, no proper empirical evidence is available to assess the productivity difference between fixed-term contracts and open-ended contracts in European countries, which explains why I prefer leave it as a free parameter in the calibration. I find a 3\% productivity deficit among temporary contracts with respect to permanent contracts. The vacancy cost represents 1.5 \% of the average wage, which is coherent with the (scarce) available evidence put forward by \citet{kramarz2010shape}.

\begin{table}[H]
\centering
\begin{tabular}{|c c c c c c c|}
\hline
$F$ & $b$ & $s$ & $\delta$ & $\rho$ & $m$ & $\gamma$\\
\hline
0.38 & 0.83 & 0.02 & 0.4 & 0.97 & 0.53 & 0.02\\
\hline
\end{tabular}
\caption{Calibrated parameters\label{calibrated}}
\end{table}

\subsection{Estimation}

The unknown parameters are related to the shock processes and the nominal rigidities. I estimate them using a Sequential Monte Carlo procedure\footnote{See \citet{RePEc:pup:pbooks:10612} for an extensive treatment of this method.}. Following \citet{thomas2009labor}, I choose the same time period extending from 1997-Q1 to 2007-Q4 and a nearly similar set of observables $\left( Y_t, \pi_t, R_t, n_t \right)$ and quarterly data series, namely GDP at constant prices, employment, EONIA rates in annual terms and the GDP deflator. All concern the 19-country Euro area and are obtained from the ECB Data Warehouse. The demeaned growth rate of the GDP deflator is plugged to inflation $\pi_t$. Since $R_t$ corresponds to the real interest rates, they correspond to the demeaned quarterly equivalent of EONIA rates diminished by estimated inflation. Real GDP and employment are logged and reluctantly linearly detrended. As a matter of fact, the use of any detrending method or filter as well as the comprehension of adequate observable equations to match growth rates in the data is mainly arbitrary and may deliver heterogeneous and mispecified estimation results. \citet{RePEc:bpj:bejmac:v:11:y:2011:i:1:n:25} and \citet{CANOVA20141} roughly propose to simultaneously estimate the parameters of flexible specifications for trends along deep parameters so as to let the model explain the part of the data it is able to account for. However, as \citet{CANOVA2009431} and \citet{ISKREV2010189, iskrev2010evaluating} testify, identification issues are real in the estimation of DSGE models. The resort to the methods advocated by \citet{RePEc:bpj:bejmac:v:11:y:2011:i:1:n:25} and \citet{CANOVA20141} would magnify these problems through the introduction of new parameters. For this reason, I stick to the detrending method employed by \citet{thomas2009labor}, which remains simple and enables comparisons between my model and their own.

Most chosen priors are chosen to be diffuse, reflecting the void of the DSGE literature with respect to dual labor markets. Thus, the priors for autocorrelations of the shock processes are uniform laws on $[0,1]$, while standard deviations follow inverse gamma distributions with mean 0.5 and standard deviation 4\footnote{Standard deviations are expressed in percentage}. As for the Taylor parameters $r_\pi$ and $r_y$, the prior needs to be vague and embed the fact that $r_\pi > 1$ and $r_y > 0$. As a result, truncated normal laws with large standard deviations are employed. \citet{DRUANT2012772} assess the average duration of firms' prices in the Euro Area to 10 months, which corresponds to a value of $\psi$ around 0.7. A tight normal law around this value is subsequently chosen.

Identification issues in DSGE models are well known. My model does not escape this observation. Following the method \citet{ISKREV2010189} makes a case for, I find that the estimated parameters are identified with the available data. Nevertheless, the implementation of methods presented by \citet{iskrev2010evaluating} reveal a few pitfalls already known in the literature. $\rho_\mu$ and $\sigma_{\mu}$ are jointly weakly identified. This problem also concerns $\rho_R$, $\rho_{\pi}$, $\rho_y$ and $\sigma_m$, whose estimation is highly intertwined. Indeed, for given data, the higher the autocorrelation of interest rates in the Taylor rule, the stronger the needed policy adjustments. In turn, this pushes up the standard deviation of monetary policy shocks.

% Table generated by Excel2LaTeX from sheet 'Feuil1'
\begin{table}[H]
\centering
\caption{Prior and posterior distributions of structural parameters.}
% Table generated by Excel2LaTeX from sheet 'Feuil1'
\begin{tabular}{ccccccccc}
\toprule
\toprule
& \multicolumn{3}{c}{ Prior distribution } &       & \multicolumn{4}{c}{ Posterior distribution } \\
\cmidrule{2-4} \cmidrule{6-9}
& Distr. & Para (1) & Para(2) &       & Mean  & Std. Dev. & 5\%   & 95\% \\
\toprule
$\rho_A$ & Uniform & 0.00  & 1.00  &       & 0.84  & 0.08  & 0.69  & 0.95 \\
$\rho_\mu$ & Uniform & 0.00  & 1.00  &       & 0.04  & 0.04  & 0.00  & 0.14 \\
$\rho_g$ & Uniform & 0.00  & 1.00  &       & 0.90  & 0.04  & 0.83  & 0.96 \\
$\rho_R$ & Uniform & 0.00  & 1.00  &       & 0.76  & 0.06  & 0.65  & 0.85 \\
$\rho_\pi$ & Normal & 1.50  & 0.75  &       & 1.82  & 0.60  & 1.08  & 3.01 \\
$\rho_y$ & Normal & 0.50  & 0.75  &       & 0.66  & 0.17  & 0.43  & 0.98 \\
$\psi$ & Beta & 0.7  & 0.1  &       & 0.79  & 0.04  & 0.85  & 0.99 \\
$\sigma_A$ & IGamma & 0.15  & 1.00  &       & 0.13  & 0.01  & 0.11  & 0.15 \\
$\sigma_\mu$ & IGamma & 0.15  & 1.00  &       & 0.26  & 0.03  & 0.22  & 0.32 \\
$\sigma_g$ & IGamma & 0.15  & 1.00  &       & 4.75  & 1.70  & 2.89  & 8.44 \\
$\sigma_m$ & IGamma & 0.15  & 1.00  &       & 0.08  & 0.01  & 0.06  & 0.10 \\
\bottomrule
\end{tabular}%
\label{estimates}
\begin{flushleft}
\footnotesize{Para(1) and Para(2) correspond to mean and standard deviation of the prior distribution if the latter is Normal or Inverse Gamma. Para(1) and Para(2) correspond to lower and upper bound of the prior distribution when the latter is uniform}
\end{flushleft}
\end{table}%

I run the Sequential Monte Carlo procedure with 1,000 likelihood-tempering steps, which involve a swarm of 100,000 particles and one Random-Walk-Metropolis-Hastings step each. The proper identification of parameters is checked for each draw from the prior distributions\footnote{Prior distributions are involved in the initialization of the swarm of particles.} and the Metropolis-Hastings steps along the method delineated by \citet{ISKREV2010189}. The results are displayed in Table \ref{estimates}. Overall, the estimates are pretty similar to those obtained by \citet{thomas2009labor}. The cost-push shocks displays virtually no autocorrelation, in opposition to productivity and government-spending shocks. The interest-rate-smoothing parameter and the price stickiness present the same order of magnitude as well. However, the standard deviations of the shocks differ significantly from their estimates, with the notable exception of monetary policy shocks. The cost-push shock displays a standard deviation of 0.26 \% instead of 10\%, while productivity shocks and government spending shocks are half as volatile. The high volatility of government-spending shocks may seem surprising. As a matter of fact, the current specification of government-spending shock could embody all demand shocks that are not explicitly modelled here but have a sizable effect on output. This may include shocks on investment, on exports or on prices of imported products for example. This problem vanishes when investment, capital, risk-aversion and habit formation are introduced in the same manner as \citet{doi:10.1111/j.1538-4616.2008.00180.x}. I prefer to display a simple model to insist on the economic phenomena specific to dual labour markets, which are relatively new in the DSGE literature. Interestingly, a marginal likelihood comparison between the classic Mortensen-Pissarides model and the current dual specification elects the latter as the most probable with respect to the data.

\bibliographystyle{elsarticle-harv}
\bibliography{ch2}

\appendix
\input{appendix}

\end{document}